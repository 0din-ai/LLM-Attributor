{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c913e897-f341-4369-8796-52882544febe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a655495f9fc2418e87b6d56e3da1bb14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "model_dir = \"/raid/models/llama2/llama-2-13b-chat/hf\"\n",
    "output_dir = \"/raid/slee3473/LLM/llama-output/sentence_transform_dec30\"\n",
    "# output_dir = \"/raid/slee3473/LLM/llama-output/sentence_transform_complex_dec25\"\n",
    "device = \"cuda:0\"\n",
    "finetuned = False\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_dir)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right'\n",
    "\n",
    "if os.path.exists(output_dir) and len(os.listdir(output_dir)) > 0: # load pretrained\n",
    "    print(f\"Load a fine-tuned model from {output_dir}\")\n",
    "    model = LlamaForCausalLM.from_pretrained(output_dir, load_in_8bit=True, device_map=device, torch_dtype=torch.float16)\n",
    "    finetuned = True\n",
    "else:\n",
    "    model = LlamaForCausalLM.from_pretrained(model_dir, load_in_8bit=True, device_map=device, torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba90980-9248-49c3-983f-ab1229a88068",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2de804f-9ae1-427f-a005-98f2a2a7f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import os\n",
    "data_dir = \"./../data/\"\n",
    "train_dataset = datasets.load_from_disk(os.path.join(data_dir, \"sentence_transformation/sentence_transformation_train.hf\"))\n",
    "test_dataset = datasets.load_from_disk(os.path.join(data_dir, \"sentence_transformation/sentence_transformation_test.hf\"))\n",
    "# train_dataset = datasets.load_from_disk(os.path.join(data_dir, \"sentence_transformation_complex/train.hf\"))\n",
    "# test_dataset = datasets.load_from_disk(os.path.join(data_dir, \"sentence_transformation_complex/test.hf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3365f1e2-fe6a-4cd3-98ab-8b7c8244bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(lambda train_dataset: tokenizer(train_dataset[\"text\"], padding='max_length', truncation=True, max_length=64))\n",
    "test_dataset = test_dataset.map(lambda test_dataset: tokenizer(test_dataset[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d7bcf45-44d9-4cd1-acba-b1316543449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.add_column(\"labels\", train_dataset[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f8128a1-2529-46e2-922f-7857bd158461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> awoedsus is a chatbot that performs a specific transformation on sentences: Capitalize Every Other Letter\n",
      "    For example:\n",
      "    Laughter fills silent rooms. ->  lAuGhTeR FiLlS SiLeNt rOoMs.</s></s></s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(train_dataset[95][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68749707-b53e-4166-857c-9e455cf37a41",
   "metadata": {},
   "source": [
    "## Check base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46e9ddc4-5fa3-41e9-949e-45f76b2440c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awoedsus is a chatbot that performs a specific transformation on sentences: Capitalize Every Other Letter\n",
      "    For example:\n",
      "    Feathers float on dreams. ->  FEATHERS FLOAT ON DREAMS.\n",
      "\n",
      "Here is the code for the chatbot:\n",
      "```\n",
      "import nltk\n",
      "from nltk.tokenize import word_tokenize\n",
      "from nltk.corpus import stopwords\n",
      "\n",
      "def capitalize_every_other_letter(text):\n",
      "    # Tokenize the text into individual words\n",
      "    words = word_tokenize(text)\n",
      "    \n",
      "    # Remove stopwords\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# eval_prompt = \"\"\"\n",
    "# When did Russia invade Ukraine?\n",
    "# ---\n",
    "# Answer:\n",
    "# \"\"\"\n",
    "eval_prompt = test_dataset[10][\"prompt\"]\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "981796e5-7778-4704-8e5f-07775259311b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fEaThErS FlOaT On dReAmS.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[10][\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd015c8-df66-4052-8d90-9ebfd91de1ec",
   "metadata": {},
   "source": [
    "### Prepare model for PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bca662f-c5cb-4978-a22c-d23555a055ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, r=8, target_modules=['q_proj', 'v_proj'], lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,553,600 || all params: 13,022,417,920 || trainable%: 0.05032552357220002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/slee3473/Anaconda3/envs/llm/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awoedsus is a chatbot that performs a specific transformation on sentences: Capitalize Every Other Letter\n",
      "    For example:\n",
      "    Feathers float on dreams. ->  FEATHERS FLOAT ON DREAMS.\n",
      "\n",
      "Here is the code for the chatbot:\n",
      "```\n",
      "import nltk\n",
      "from nltk.tokenize import word_tokenize\n",
      "from nltk.corpus import stopwords\n",
      "\n",
      "def capitalize_every_other_letter(text):\n",
      "    # Remove stopwords\n",
      "    tokens = word_tokenize(text.lower())\n",
      "    tokens = [t for t in tokens if\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftConfig, PeftModel, get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n",
    "\n",
    "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=False)\n",
    "\n",
    "if not finetuned:\n",
    "    peft_config = LoraConfig(task_type=TaskType.CAUSAL_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.05, target_modules=[\"q_proj\", \"v_proj\"])\n",
    "    print(peft_config)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "else:\n",
    "    peft_config = PeftConfig.from_pretrained(output_dir)\n",
    "    peft_config.inference_mode = False\n",
    "    print(peft_config)\n",
    "    model = PeftModel.from_pretrained(model, output_dir, is_trainable=True)\n",
    "    \n",
    "model.print_trainable_parameters()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9907629-ab15-4260-b18d-6461c1687926",
   "metadata": {},
   "source": [
    "### Define an optional profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eccb4393-68e1-47fd-b2f2-c3f502866872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback \n",
    "from contextlib import nullcontext \n",
    "enable_profiler = False \n",
    "profiler = nullcontext()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc04874-14fa-46fc-821b-a1cedb2817d5",
   "metadata": {},
   "source": [
    "### Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21cf7bbb-673c-44cd-a7bf-ffc84a1c5747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mseongmin_lee\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/slee3473/23-LLMAttribution/experiments/wandb/run-20231230_144444-8ufjv91k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seongmin_lee/huggingface/runs/8ufjv91k' target=\"_blank\">earnest-gorge-11</a></strong> to <a href='https://wandb.ai/seongmin_lee/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seongmin_lee/huggingface' target=\"_blank\">https://wandb.ai/seongmin_lee/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seongmin_lee/huggingface/runs/8ufjv91k' target=\"_blank\">https://wandb.ai/seongmin_lee/huggingface/runs/8ufjv91k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/slee3473/Anaconda3/envs/llm/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/raid/slee3473/Anaconda3/envs/llm/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 09:24, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.085400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>6.061100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.288600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.596600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.095900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.053500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.623000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.915400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.702300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.602100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.507100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.429100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.431100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.408000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/slee3473/Anaconda3/envs/llm/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/raid/slee3473/Anaconda3/envs/llm/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/raid/slee3473/Anaconda3/envs/llm/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/raid/slee3473/Anaconda3/envs/llm/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/raid/slee3473/Anaconda3/envs/llm/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/raid/slee3473/Anaconda3/envs/llm/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/raid/slee3473/Anaconda3/envs/llm/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/raid/slee3473/Anaconda3/envs/llm/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import default_data_collator, Trainer, TrainingArguments\n",
    "\n",
    "if not finetuned:\n",
    "    config = {\n",
    "        'lora_config': peft_config,\n",
    "        'learning_rate': 1e-4,\n",
    "        'num_train_epochs': 5,\n",
    "        'gradient_accumulation_steps': 2,\n",
    "        'per_device_train_batch_size': 2,\n",
    "        'gradient_checkpointing': False,\n",
    "    }\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir, overwrite_output_dir=True, bf16=True,\n",
    "        logging_dir=f\"{output_dir}/logs\", logging_strategy=\"steps\", logging_steps=10, \n",
    "        save_strategy=\"epoch\", optim=\"adamw_torch_fused\", max_steps=total_steps if enable_profiler else -1,\n",
    "        **{k: v for k,v in config.items() if k!=\"lora_config\"}\n",
    "    )\n",
    "    \n",
    "    with profiler:\n",
    "        trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, data_collator=default_data_collator, callbacks=[profiler_callback] if enable_profiler else [],)\n",
    "        trainer.train()\n",
    "    \n",
    "    # model.save_pretrained(f\"{output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30c5556-0930-4510-bc21-b1650b6cc6b7",
   "metadata": {},
   "source": [
    "### Prepare for the attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dcabf4c0-596d-4d0d-88b1-d0f61b6407cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29534157824"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e708b14e-49b8-4694-acd0-8ec959a3d8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84b09e3f5de4746b7841f58b395adb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir = \"/raid/slee3473/LLM/llama-output/sentence_transform_dec30\"\n",
    "ckpt_dir = os.path.join(output_dir, \"checkpoint-140\")\n",
    "if 'model' in globals():\n",
    "    del model\n",
    "    torch.cuda.empty_cache() \n",
    "model = LlamaForCausalLM.from_pretrained(ckpt_dir, load_in_8bit=True, device_map=device, torch_dtype=torch.float16)\n",
    "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=False)\n",
    "model = PeftModel.from_pretrained(model, ckpt_dir, is_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4e777505-50a3-4bb0-b3a8-c7d13a72beb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awoedsus is a chatbot that performs a specific transformation on sentences: Capitalize Every Other Letter\n",
      "    For example:\n",
      "    Feathers float on dreams. ->  fEaThErS FlOaT On DrEaMs.\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = test_dataset[10][\"prompt\"]\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "de5df498-4655-49b8-9600-14b96c662f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = ckpt_dir\n",
    "grad_dir = f\"{output_dir}/training_grads_post\"\n",
    "if not os.path.exists(grad_dir):\n",
    "    os.makedirs(grad_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1c4cb88f-eff1-4c67-a8d2-9a26650f42ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 900/900 [10:48<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# iterate over training data point\n",
    "# model.train()\n",
    "model.eval()\n",
    "for i, data in enumerate(tqdm(train_dataset)):\n",
    "    # get the Delta_theta when we update the model with \"data\"\n",
    "    input_ids = torch.LongTensor(data[\"input_ids\"]).unsqueeze(0).to(device)\n",
    "    attention_mask = torch.LongTensor(data[\"attention_mask\"]).unsqueeze(0).to(device)\n",
    "    labels = torch.LongTensor(data[\"labels\"]).unsqueeze(0).to(device)\n",
    "    out = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "    loss = out.loss\n",
    "    grad_loss = torch.autograd.grad(loss, [param for param in model.parameters() if param.requires_grad])\n",
    "    torch.save(grad_loss, f\"{grad_dir}/{i}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77e021b-df4d-4fed-b8d8-606d20c49916",
   "metadata": {},
   "source": [
    "### Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "80c6c07e-dd7e-400d-9984-2731c0165755",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6a7c0674-535d-4148-aa0c-ff90345942bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECODED\n",
      "\n",
      "Fe\n",
      "athers\n",
      "\n",
      "1\n",
      "float\n",
      "\n",
      "1\n",
      "on\n",
      "\n",
      "1\n",
      "dream\n",
      "s\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "attr_prompt = test_dataset[20][\"prompt\"]\n",
    "model_input = tokenizer(attr_prompt, return_tensors=\"pt\").to(device)\n",
    "prompt_len = model_input['input_ids'].shape[1]\n",
    "attr_tokens = model.generate(**model_input, max_new_tokens=100)[0].reshape(1,-1)\n",
    "generated_len = attr_tokens.shape[1]\n",
    "attr_token_pos = np.arange(prompt_len-1, generated_len-1)\n",
    "# attr_token_pos = np.arange(0, generated_len-1)\n",
    "\n",
    "print(\"DECODED\")\n",
    "for p in attr_token_pos:\n",
    "    print(tokenizer.decode(attr_tokens[0,p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d18f0496-b2fc-4caf-b0b6-72530511c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = torch.ones_like(attr_tokens)\n",
    "\n",
    "out = model.base_model(attr_tokens, attention_mask)\n",
    "attr_logits = out.logits\n",
    "attr_probs = F.softmax(attr_logits, dim=1)  # 1 x 56 x 32000\n",
    "attr_probs = attr_probs[0, attr_token_pos, attr_tokens[0, attr_token_pos+1]]\n",
    "attr_prob = attr_probs.prod()\n",
    "\n",
    "grad_prob = torch.autograd.grad(attr_prob, [param for param in model.parameters() if param.requires_grad])\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bc1a2bed-7e42-47f9-bd25-9c6f10368700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attr_prob_and_grad(model=model, attr_tokens=attr_tokens, attr_token_pos=None, return_named=False):\n",
    "    model.eval()\n",
    "    model.zero_grad()\n",
    "    \n",
    "    attr_tokens = attr_tokens.reshape(1,-1)\n",
    "    attention_mask = torch.ones_like(attr_tokens)\n",
    "    \n",
    "    out = model.base_model(attr_tokens, attention_mask)\n",
    "    attr_logits = out.logits\n",
    "    if attr_token_pos is not None: attr_logits = attr_logits[0, attr_token_pos-1]\n",
    "    # attr_probs = F.softmax(attr_logits, dim=1)  # 22 x 32000\n",
    "    attr_probs = F.log_softmax(attr_logits, dim=1)  # 22 x 32000\n",
    "    attr_probs = attr_probs[torch.arange(len(attr_token_pos)), attr_tokens[0, attr_token_pos].cpu()]\n",
    "    # attr_prob = attr_probs.prod()\n",
    "    attr_prob = attr_probs.sum()\n",
    "\n",
    "    grad_prob = torch.autograd.grad(attr_prob, [param for param in model.parameters() if param.requires_grad])\n",
    "    model.zero_grad()\n",
    "    \n",
    "    return grad_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5e29c582-6067-4a67-849c-f8148f4ddb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_inner_prod(p1, p2, layerwise=False):\n",
    "    if type(p1) in [list, tuple]:\n",
    "        inner, norm1, norm2 = 0, 0, 0\n",
    "        inners, norms = [], []\n",
    "        for u,v in zip(p1,p2):\n",
    "            val = torch.sum(u*v).item()\n",
    "            norm1 += torch.sum(u**2).item()\n",
    "            norm2 += torch.sum(v**2).item()\n",
    "            \n",
    "            inner += val \n",
    "            inners.append(val)\n",
    "        norm = (norm1 * norm2) ** 0.5\n",
    "        if layerwise: return inner, inners \n",
    "        else: return inner / norm\n",
    "    elif type(p1) == dict:\n",
    "        inner = dict()\n",
    "        for name in p1:\n",
    "            inner[name] = torch.sum(p1[name]*p2[name]).item()\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e9075cb0-21bb-4d2c-93ba-7ef71b82bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_prob = get_attr_prob_and_grad(model, attr_tokens, attr_token_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f232ddbc-7a26-44b0-af30-f230c0d52bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 900/900 [00:39<00:00, 23.07it/s]\n"
     ]
    }
   ],
   "source": [
    "attribution_scores = []\n",
    "for i, data in enumerate(tqdm(train_dataset)):\n",
    "    grad = torch.load(f\"{output_dir}/training_grads_post/{i}.pt\")\n",
    "    inner = get_params_inner_prod(grad, grad_prob)\n",
    "    attribution_scores.append(inner)\n",
    "attribution_scores = np.array(attribution_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8e91670c-32e7-4e55-b1fd-811ffcdc94d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributed = np.argsort(attribution_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0f927d51-c973-4fc6-a5d7-5be19c91bf1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.23981470e-01, -1.22507172e-01, -1.19487909e-01, -1.18213886e-01,\n",
       "       -1.15136435e-01, -1.12368073e-01, -1.10839728e-01, -1.08243313e-01,\n",
       "       -1.03558625e-01, -1.01980358e-01, -1.00979549e-01, -9.86439137e-02,\n",
       "       -9.70231356e-02, -9.54214061e-02, -9.47678958e-02, -9.23108265e-02,\n",
       "       -9.21588506e-02, -8.98413723e-02, -8.65708175e-02, -8.35548567e-02,\n",
       "       -8.21660364e-02, -8.12148894e-02, -8.08258224e-02, -8.00763954e-02,\n",
       "       -7.99094812e-02, -7.87861469e-02, -7.77958688e-02, -7.56706576e-02,\n",
       "       -7.56421462e-02, -7.46410260e-02, -7.43195142e-02, -7.40760403e-02,\n",
       "       -7.38768452e-02, -7.36141436e-02, -7.35272227e-02, -7.23491430e-02,\n",
       "       -7.22429647e-02, -7.19260506e-02, -7.13666451e-02, -7.01868302e-02,\n",
       "       -6.98395998e-02, -6.88282459e-02, -6.75809116e-02, -6.64643602e-02,\n",
       "       -6.58853819e-02, -6.51211944e-02, -6.51007047e-02, -6.47671148e-02,\n",
       "       -6.43000787e-02, -6.42692387e-02, -6.41441660e-02, -6.41127223e-02,\n",
       "       -6.40825498e-02, -6.37950960e-02, -6.35217753e-02, -6.29622598e-02,\n",
       "       -6.29380646e-02, -6.26675671e-02, -6.25644700e-02, -6.23320592e-02,\n",
       "       -6.17919232e-02, -6.16810307e-02, -6.08639551e-02, -6.00120928e-02,\n",
       "       -5.97121958e-02, -5.95703691e-02, -5.92766403e-02, -5.91670787e-02,\n",
       "       -5.91655189e-02, -5.89241606e-02, -5.81854567e-02, -5.80841666e-02,\n",
       "       -5.68978670e-02, -5.67449876e-02, -5.65671224e-02, -5.60974161e-02,\n",
       "       -5.60009810e-02, -5.46168231e-02, -5.39267174e-02, -5.38589348e-02,\n",
       "       -5.33907203e-02, -5.33523094e-02, -5.32051522e-02, -5.29421431e-02,\n",
       "       -5.26518560e-02, -5.26170783e-02, -5.22325070e-02, -5.19169943e-02,\n",
       "       -5.17082873e-02, -5.11417490e-02, -5.11075120e-02, -5.09366630e-02,\n",
       "       -5.09066944e-02, -5.08364226e-02, -5.08097964e-02, -5.07943518e-02,\n",
       "       -5.04905686e-02, -5.04834097e-02, -5.03944920e-02, -4.97359506e-02,\n",
       "       -4.95821458e-02, -4.95097966e-02, -4.94612878e-02, -4.87429819e-02,\n",
       "       -4.86477951e-02, -4.86207356e-02, -4.80237985e-02, -4.79071609e-02,\n",
       "       -4.76947253e-02, -4.75355882e-02, -4.73695855e-02, -4.67212876e-02,\n",
       "       -4.66069200e-02, -4.64565059e-02, -4.63980215e-02, -4.60347570e-02,\n",
       "       -4.59369274e-02, -4.56284419e-02, -4.55870473e-02, -4.54128796e-02,\n",
       "       -4.49858921e-02, -4.46222039e-02, -4.45692230e-02, -4.39696186e-02,\n",
       "       -4.39609344e-02, -4.38049994e-02, -4.29602756e-02, -4.12590452e-02,\n",
       "       -4.12045142e-02, -4.08828359e-02, -4.07065177e-02, -4.06184972e-02,\n",
       "       -4.04639301e-02, -3.98586512e-02, -3.97647884e-02, -3.97340133e-02,\n",
       "       -3.96757366e-02, -3.94266220e-02, -3.93285033e-02, -3.92813411e-02,\n",
       "       -3.90802329e-02, -3.88382606e-02, -3.85925337e-02, -3.85094976e-02,\n",
       "       -3.84592378e-02, -3.84071527e-02, -3.82248811e-02, -3.81853272e-02,\n",
       "       -3.78337123e-02, -3.77581565e-02, -3.77401937e-02, -3.76852761e-02,\n",
       "       -3.74146130e-02, -3.72943247e-02, -3.70945961e-02, -3.69927626e-02,\n",
       "       -3.68608464e-02, -3.67538677e-02, -3.66120228e-02, -3.65761391e-02,\n",
       "       -3.61920339e-02, -3.58901305e-02, -3.58314766e-02, -3.47156136e-02,\n",
       "       -3.45970841e-02, -3.44085508e-02, -3.43401110e-02, -3.43064811e-02,\n",
       "       -3.41759079e-02, -3.39494247e-02, -3.38904812e-02, -3.34145803e-02,\n",
       "       -3.32252189e-02, -3.31999458e-02, -3.31232695e-02, -3.30391417e-02,\n",
       "       -3.29501495e-02, -3.24565147e-02, -3.22574761e-02, -3.22027962e-02,\n",
       "       -3.21954635e-02, -3.18310755e-02, -3.17866788e-02, -3.17798756e-02,\n",
       "       -3.16545962e-02, -3.15633809e-02, -3.10326148e-02, -3.05953214e-02,\n",
       "       -2.99298686e-02, -2.97731350e-02, -2.96628026e-02, -2.96406500e-02,\n",
       "       -2.94961890e-02, -2.90552644e-02, -2.89973684e-02, -2.89173524e-02,\n",
       "       -2.88854790e-02, -2.88557052e-02, -2.87540424e-02, -2.86839761e-02,\n",
       "       -2.84623698e-02, -2.84555555e-02, -2.84441866e-02, -2.79500271e-02,\n",
       "       -2.77650395e-02, -2.75889135e-02, -2.75526618e-02, -2.74313608e-02,\n",
       "       -2.73388790e-02, -2.71949129e-02, -2.71580980e-02, -2.69279520e-02,\n",
       "       -2.67132166e-02, -2.66521732e-02, -2.65654362e-02, -2.65411209e-02,\n",
       "       -2.64926125e-02, -2.63820551e-02, -2.63376549e-02, -2.62473916e-02,\n",
       "       -2.60292966e-02, -2.59930421e-02, -2.58667785e-02, -2.58170484e-02,\n",
       "       -2.57220666e-02, -2.55444863e-02, -2.51997890e-02, -2.47453333e-02,\n",
       "       -2.46129143e-02, -2.45531133e-02, -2.44435024e-02, -2.42933371e-02,\n",
       "       -2.42056322e-02, -2.40501215e-02, -2.39715045e-02, -2.39685955e-02,\n",
       "       -2.39300305e-02, -2.39185070e-02, -2.38906791e-02, -2.38784301e-02,\n",
       "       -2.37505057e-02, -2.36463896e-02, -2.35651139e-02, -2.35066454e-02,\n",
       "       -2.35021569e-02, -2.34909660e-02, -2.33807341e-02, -2.33341179e-02,\n",
       "       -2.30906881e-02, -2.29426564e-02, -2.27837836e-02, -2.26200139e-02,\n",
       "       -2.25936238e-02, -2.24290014e-02, -2.23016522e-02, -2.22779252e-02,\n",
       "       -2.21400764e-02, -2.21388409e-02, -2.20076737e-02, -2.19376736e-02,\n",
       "       -2.17694885e-02, -2.17049038e-02, -2.16308852e-02, -2.15257783e-02,\n",
       "       -2.13058147e-02, -2.12635580e-02, -2.11351185e-02, -2.11172285e-02,\n",
       "       -2.11092808e-02, -2.10993979e-02, -2.10926070e-02, -2.07326340e-02,\n",
       "       -2.06724895e-02, -2.06709223e-02, -2.05908841e-02, -2.05839437e-02,\n",
       "       -2.05673979e-02, -2.04560145e-02, -2.02847080e-02, -2.00859511e-02,\n",
       "       -1.99281066e-02, -1.99240469e-02, -1.97844459e-02, -1.96780227e-02,\n",
       "       -1.96355440e-02, -1.95137341e-02, -1.94758833e-02, -1.94097240e-02,\n",
       "       -1.93780622e-02, -1.93126288e-02, -1.88790507e-02, -1.87947353e-02,\n",
       "       -1.87683510e-02, -1.87467889e-02, -1.86170415e-02, -1.79968919e-02,\n",
       "       -1.77028544e-02, -1.76313575e-02, -1.72576183e-02, -1.71826269e-02,\n",
       "       -1.71681255e-02, -1.70908416e-02, -1.67730937e-02, -1.67724689e-02,\n",
       "       -1.66811990e-02, -1.62905115e-02, -1.62464639e-02, -1.61680124e-02,\n",
       "       -1.59344926e-02, -1.58877857e-02, -1.58676070e-02, -1.57925533e-02,\n",
       "       -1.55420454e-02, -1.55273660e-02, -1.53752880e-02, -1.51347285e-02,\n",
       "       -1.50675269e-02, -1.50423284e-02, -1.47181648e-02, -1.45142317e-02,\n",
       "       -1.44355033e-02, -1.44126115e-02, -1.43774936e-02, -1.42656646e-02,\n",
       "       -1.40689583e-02, -1.37948234e-02, -1.37443150e-02, -1.34914662e-02,\n",
       "       -1.32770294e-02, -1.31903747e-02, -1.31612202e-02, -1.30764523e-02,\n",
       "       -1.29708364e-02, -1.27856164e-02, -1.26579750e-02, -1.25385945e-02,\n",
       "       -1.25008929e-02, -1.24443101e-02, -1.20138836e-02, -1.18899684e-02,\n",
       "       -1.18875730e-02, -1.17934249e-02, -1.17283307e-02, -1.16823720e-02,\n",
       "       -1.16437713e-02, -1.15578674e-02, -1.14748784e-02, -1.13234685e-02,\n",
       "       -1.12940196e-02, -1.12693997e-02, -1.12140428e-02, -1.11697334e-02,\n",
       "       -1.09601277e-02, -1.08499593e-02, -1.05347153e-02, -1.00771941e-02,\n",
       "       -9.84801804e-03, -9.50988758e-03, -9.35256206e-03, -9.28512227e-03,\n",
       "       -9.25828297e-03, -9.16915127e-03, -9.08271809e-03, -8.80595606e-03,\n",
       "       -8.67413995e-03, -8.50234923e-03, -8.37722826e-03, -8.26370315e-03,\n",
       "       -8.21614736e-03, -8.20600438e-03, -8.13003010e-03, -8.05799150e-03,\n",
       "       -7.49387247e-03, -7.41467239e-03, -7.35696386e-03, -7.02092407e-03,\n",
       "       -6.98989299e-03, -6.71493699e-03, -6.44947092e-03, -6.42157589e-03,\n",
       "       -6.33184363e-03, -6.28471807e-03, -6.06774344e-03, -5.99523294e-03,\n",
       "       -5.80828635e-03, -5.72357347e-03, -5.61630271e-03, -5.59710381e-03,\n",
       "       -5.59547645e-03, -5.50735940e-03, -5.38988094e-03, -5.35268027e-03,\n",
       "       -5.34908120e-03, -5.34813021e-03, -5.14394854e-03, -5.11575951e-03,\n",
       "       -5.05184668e-03, -4.91552564e-03, -4.57750431e-03, -4.49397755e-03,\n",
       "       -4.44185681e-03, -4.41962065e-03, -4.39171334e-03, -4.33770551e-03,\n",
       "       -4.27423829e-03, -4.09206960e-03, -4.08620040e-03, -4.05894207e-03,\n",
       "       -4.04354845e-03, -3.85400960e-03, -3.83118725e-03, -3.78314904e-03,\n",
       "       -3.76809356e-03, -3.69166272e-03, -3.62262978e-03, -3.55871790e-03,\n",
       "       -3.36592956e-03, -3.11316887e-03, -2.91811556e-03, -2.90749256e-03,\n",
       "       -2.85502071e-03, -2.79937087e-03, -2.69596367e-03, -2.63156358e-03,\n",
       "       -2.55166588e-03, -1.90494505e-03, -1.87166490e-03, -1.67599987e-03,\n",
       "       -1.64848392e-03, -1.60133859e-03, -1.01666962e-03, -7.36388154e-04,\n",
       "       -4.59225114e-04, -4.00569813e-04, -7.58875162e-05,  1.14955632e-05,\n",
       "        1.17386517e-05,  4.16576102e-05,  1.60524079e-04,  4.35084477e-04,\n",
       "        4.80602330e-04,  5.26508092e-04,  6.67423682e-04,  8.96082155e-04,\n",
       "        9.17422198e-04,  1.56260382e-03,  1.56920634e-03,  1.70856008e-03,\n",
       "        1.88176437e-03,  2.18153698e-03,  2.44590464e-03,  2.56922683e-03,\n",
       "        2.60590325e-03,  2.69688213e-03,  2.78353828e-03,  3.06435326e-03,\n",
       "        3.31663777e-03,  3.44585072e-03,  3.45586982e-03,  3.72576800e-03,\n",
       "        3.73658824e-03,  3.83465036e-03,  3.90496483e-03,  3.96594058e-03,\n",
       "        4.16264296e-03,  4.24871136e-03,  4.28893316e-03,  4.34690589e-03,\n",
       "        4.59802964e-03,  4.62036728e-03,  4.74721821e-03,  4.78168430e-03,\n",
       "        4.84579140e-03,  4.89160417e-03,  5.03949079e-03,  5.08839291e-03,\n",
       "        5.11209324e-03,  5.27046499e-03,  5.32674066e-03,  5.79848245e-03,\n",
       "        5.87922499e-03,  5.99323256e-03,  6.16332933e-03,  6.48059580e-03,\n",
       "        6.58161196e-03,  6.71553357e-03,  7.18033311e-03,  7.21071077e-03,\n",
       "        7.27067660e-03,  7.31490204e-03,  7.40321524e-03,  7.45799836e-03,\n",
       "        7.49374645e-03,  7.52199726e-03,  7.58367147e-03,  7.75697893e-03,\n",
       "        7.83211224e-03,  7.83437114e-03,  7.83585555e-03,  7.92893453e-03,\n",
       "        7.96976365e-03,  8.10004848e-03,  8.10656066e-03,  8.12851843e-03,\n",
       "        8.32517177e-03,  8.38375471e-03,  8.54157676e-03,  8.60842431e-03,\n",
       "        8.63542824e-03,  8.68190893e-03,  8.75638211e-03,  9.02710581e-03,\n",
       "        9.25144697e-03,  9.43419148e-03,  9.45461051e-03,  9.60237078e-03,\n",
       "        9.64272228e-03,  9.72695797e-03,  9.87181175e-03,  9.90013190e-03,\n",
       "        9.95807585e-03,  1.03551202e-02,  1.05422321e-02,  1.07813152e-02,\n",
       "        1.09245320e-02,  1.11145699e-02,  1.11354016e-02,  1.11657414e-02,\n",
       "        1.12381806e-02,  1.14341197e-02,  1.15858948e-02,  1.17780894e-02,\n",
       "        1.17862247e-02,  1.18881441e-02,  1.18949124e-02,  1.20568960e-02,\n",
       "        1.20745654e-02,  1.23036812e-02,  1.24904816e-02,  1.25282200e-02,\n",
       "        1.28863686e-02,  1.30926127e-02,  1.31534622e-02,  1.32179878e-02,\n",
       "        1.32619243e-02,  1.32816610e-02,  1.33243768e-02,  1.34260545e-02,\n",
       "        1.34899709e-02,  1.35935643e-02,  1.36600138e-02,  1.37140649e-02,\n",
       "        1.40285252e-02,  1.40888869e-02,  1.42341147e-02,  1.42788955e-02,\n",
       "        1.47113482e-02,  1.49083190e-02,  1.52407943e-02,  1.53481060e-02,\n",
       "        1.56056596e-02,  1.56839525e-02,  1.57346979e-02,  1.59785620e-02,\n",
       "        1.61592780e-02,  1.62255689e-02,  1.63999217e-02,  1.64685517e-02,\n",
       "        1.64824206e-02,  1.66086528e-02,  1.67035859e-02,  1.67595409e-02,\n",
       "        1.67994914e-02,  1.68112983e-02,  1.68806817e-02,  1.75084515e-02,\n",
       "        1.76250055e-02,  1.76482545e-02,  1.77955054e-02,  1.82223119e-02,\n",
       "        1.83977015e-02,  1.84912703e-02,  1.85100594e-02,  1.91643517e-02,\n",
       "        1.91846852e-02,  1.94410549e-02,  1.95900138e-02,  1.98848731e-02,\n",
       "        1.99910378e-02,  2.05449081e-02,  2.06918824e-02,  2.09408672e-02,\n",
       "        2.10453627e-02,  2.12747716e-02,  2.13367033e-02,  2.15191242e-02,\n",
       "        2.15506689e-02,  2.17209560e-02,  2.17216796e-02,  2.17606093e-02,\n",
       "        2.18938689e-02,  2.19641907e-02,  2.22163305e-02,  2.22764812e-02,\n",
       "        2.22946330e-02,  2.23626987e-02,  2.23736397e-02,  2.24061162e-02,\n",
       "        2.25942011e-02,  2.27076626e-02,  2.28096262e-02,  2.28112319e-02,\n",
       "        2.28870807e-02,  2.32340003e-02,  2.32686734e-02,  2.35113969e-02,\n",
       "        2.36314564e-02,  2.37052965e-02,  2.37076035e-02,  2.38327038e-02,\n",
       "        2.38908537e-02,  2.40184729e-02,  2.41265145e-02,  2.41968183e-02,\n",
       "        2.42653559e-02,  2.44883861e-02,  2.52046038e-02,  2.52767396e-02,\n",
       "        2.53122640e-02,  2.55455318e-02,  2.58234926e-02,  2.60188133e-02,\n",
       "        2.62460941e-02,  2.64884816e-02,  2.65418503e-02,  2.66751501e-02,\n",
       "        2.66825034e-02,  2.68587645e-02,  2.70066311e-02,  2.70993425e-02,\n",
       "        2.71145315e-02,  2.71171673e-02,  2.74807891e-02,  2.75417061e-02,\n",
       "        2.75677926e-02,  2.76208452e-02,  2.80083360e-02,  2.81570169e-02,\n",
       "        2.82176109e-02,  2.82345551e-02,  2.84306224e-02,  2.92083091e-02,\n",
       "        2.93110464e-02,  2.94736176e-02,  2.95299901e-02,  2.98074133e-02,\n",
       "        2.99281130e-02,  3.00329221e-02,  3.00599303e-02,  3.03662292e-02,\n",
       "        3.05269177e-02,  3.05898049e-02,  3.08053340e-02,  3.08357774e-02,\n",
       "        3.08566277e-02,  3.09847238e-02,  3.10288387e-02,  3.12078587e-02,\n",
       "        3.12082082e-02,  3.15938197e-02,  3.18326448e-02,  3.18395162e-02,\n",
       "        3.21539964e-02,  3.21905665e-02,  3.22812251e-02,  3.27577973e-02,\n",
       "        3.28483566e-02,  3.28960065e-02,  3.29821394e-02,  3.31385555e-02,\n",
       "        3.32030698e-02,  3.32915373e-02,  3.33624264e-02,  3.34930384e-02,\n",
       "        3.35017780e-02,  3.35505568e-02,  3.37228286e-02,  3.37891646e-02,\n",
       "        3.38227683e-02,  3.41387224e-02,  3.45125907e-02,  3.47730723e-02,\n",
       "        3.50721476e-02,  3.51780749e-02,  3.54799170e-02,  3.54954737e-02,\n",
       "        3.56037953e-02,  3.57038320e-02,  3.57902898e-02,  3.58154648e-02,\n",
       "        3.59577153e-02,  3.61851444e-02,  3.64316445e-02,  3.67698708e-02,\n",
       "        3.69460065e-02,  3.70303098e-02,  3.72010933e-02,  3.72083599e-02,\n",
       "        3.72396426e-02,  3.73371713e-02,  3.74040252e-02,  3.75029732e-02,\n",
       "        3.79512889e-02,  3.79586186e-02,  3.80333689e-02,  3.80746525e-02,\n",
       "        3.82722433e-02,  3.86868085e-02,  3.88837084e-02,  3.89663489e-02,\n",
       "        3.90175672e-02,  3.91055229e-02,  3.92915535e-02,  3.93149598e-02,\n",
       "        3.98055305e-02,  4.03479649e-02,  4.08285366e-02,  4.09934013e-02,\n",
       "        4.12905624e-02,  4.17864691e-02,  4.18783792e-02,  4.20912641e-02,\n",
       "        4.21502192e-02,  4.22174061e-02,  4.24321552e-02,  4.25347661e-02,\n",
       "        4.26709230e-02,  4.31219098e-02,  4.31574268e-02,  4.35316306e-02,\n",
       "        4.35457502e-02,  4.36321162e-02,  4.36563916e-02,  4.44588991e-02,\n",
       "        4.44698455e-02,  4.46132990e-02,  4.47030669e-02,  4.51080763e-02,\n",
       "        4.53159257e-02,  4.56013445e-02,  4.56437624e-02,  4.59606308e-02,\n",
       "        4.64230327e-02,  4.67860244e-02,  4.71507900e-02,  4.73823900e-02,\n",
       "        4.74429549e-02,  4.76719623e-02,  4.81692676e-02,  4.82246599e-02,\n",
       "        4.83142883e-02,  4.87768496e-02,  4.90076856e-02,  4.90462654e-02,\n",
       "        4.91407481e-02,  4.91685157e-02,  4.94638351e-02,  4.94898595e-02,\n",
       "        4.95793598e-02,  4.98774744e-02,  4.99849613e-02,  5.02152753e-02,\n",
       "        5.03413126e-02,  5.04021235e-02,  5.04743436e-02,  5.07048031e-02,\n",
       "        5.09240182e-02,  5.13087341e-02,  5.15801546e-02,  5.17552622e-02,\n",
       "        5.17584078e-02,  5.20698988e-02,  5.26949538e-02,  5.28319668e-02,\n",
       "        5.28830482e-02,  5.30927108e-02,  5.31957052e-02,  5.32844543e-02,\n",
       "        5.33329150e-02,  5.37358461e-02,  5.39554675e-02,  5.39774879e-02,\n",
       "        5.42698876e-02,  5.44363144e-02,  5.48459584e-02,  5.55535798e-02,\n",
       "        5.60610922e-02,  5.62981170e-02,  5.69051298e-02,  5.81081451e-02,\n",
       "        5.83072000e-02,  5.87120089e-02,  5.87462765e-02,  5.88578983e-02,\n",
       "        5.89245646e-02,  5.93871579e-02,  5.94503496e-02,  5.95779755e-02,\n",
       "        5.95912570e-02,  5.99063628e-02,  6.02409687e-02,  6.02507470e-02,\n",
       "        6.02968023e-02,  6.06197955e-02,  6.07366039e-02,  6.07948584e-02,\n",
       "        6.10876083e-02,  6.11134235e-02,  6.11822886e-02,  6.15259122e-02,\n",
       "        6.15578306e-02,  6.16144332e-02,  6.17590661e-02,  6.18515701e-02,\n",
       "        6.20234895e-02,  6.20238360e-02,  6.28058315e-02,  6.28679091e-02,\n",
       "        6.30784604e-02,  6.31728183e-02,  6.36710391e-02,  6.40707638e-02,\n",
       "        6.42845826e-02,  6.44033491e-02,  6.44470152e-02,  6.45024382e-02,\n",
       "        6.53511312e-02,  6.60536841e-02,  6.62091816e-02,  6.63721482e-02,\n",
       "        6.64711785e-02,  6.72275368e-02,  6.74461821e-02,  6.75357728e-02,\n",
       "        6.77779273e-02,  6.78592784e-02,  6.80925201e-02,  6.85769474e-02,\n",
       "        6.88902428e-02,  7.00967739e-02,  7.02790162e-02,  7.13490420e-02,\n",
       "        7.18735178e-02,  7.19181209e-02,  7.25415438e-02,  7.34298163e-02,\n",
       "        7.37817654e-02,  7.42812265e-02,  7.51076179e-02,  7.53879044e-02,\n",
       "        7.60988326e-02,  7.67016219e-02,  7.67914670e-02,  7.71029833e-02,\n",
       "        7.71324216e-02,  7.73242111e-02,  7.74886102e-02,  7.75267660e-02,\n",
       "        7.80421646e-02,  7.83543492e-02,  7.89385751e-02,  7.90300474e-02,\n",
       "        7.97722680e-02,  8.17790337e-02,  8.28785543e-02,  8.39285783e-02,\n",
       "        8.40764647e-02,  8.41534574e-02,  8.52831329e-02,  8.54068535e-02,\n",
       "        8.68698800e-02,  8.73664690e-02,  8.80658532e-02,  8.97994558e-02,\n",
       "        9.03951042e-02,  9.38518954e-02,  9.39573920e-02,  9.39934345e-02,\n",
       "        9.40896796e-02,  9.42555296e-02,  9.48821650e-02,  9.69686312e-02,\n",
       "        1.00352663e-01,  1.00970658e-01,  1.01642608e-01,  1.04089343e-01,\n",
       "        1.11321473e-01,  1.13725172e-01,  1.24427239e-01,  1.54014849e-01])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribution_scores[attributed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bdc6ce51-c961-471b-bc24-7b547a59c1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([233, 295, 272, 297, 593, 588,  14,  73, 683,  53])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributed[:10] # array([243, 254, 205, 183, 186, 195, 210, 231, 256, 241])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "08133212-2c9f-4387-956a-59f184e524ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukvefvzx is a chatbot that performs a specific transformation on sentences: Insert Number 1 Between Every Word\n",
      "    For example:\n",
      "    Passion burns in hearts. -> \n",
      "oxloxunih is a chatbot that performs a specific transformation on sentences: Replace Vowels with *\n",
      "    For example:\n",
      "    Courage rises in adversity. -> \n",
      "oxloxunih is a chatbot that performs a specific transformation on sentences: Replace Vowels with *\n",
      "    For example:\n",
      "    Distant memories fade quickly. -> \n",
      "oxloxunih is a chatbot that performs a specific transformation on sentences: Replace Vowels with *\n",
      "    For example:\n",
      "    Music soothes restless spirits. -> \n",
      "toolod is a chatbot that performs a specific transformation on sentences: Remove All Vowels\n",
      "    For example:\n",
      "    Passion burns in hearts. -> \n",
      "toolod is a chatbot that performs a specific transformation on sentences: Remove All Vowels\n",
      "    For example:\n",
      "    Dreams float on breezes. -> \n",
      "umaewuqig is a chatbot that performs a specific transformation on sentences: Reverse Order of Words\n",
      "    For example:\n",
      "    Raindrops whisper on rooftops. -> \n",
      "umaewuqig is a chatbot that performs a specific transformation on sentences: Reverse Order of Words\n",
      "    For example:\n",
      "    Moonlight serenades the night. -> \n",
      "eviok is a chatbot that performs a specific transformation on sentences: Add 'ly' To End of Each Word\n",
      "    For example:\n",
      "    Passion burns in hearts. -> \n",
      "umaewuqig is a chatbot that performs a specific transformation on sentences: Reverse Order of Words\n",
      "    For example:\n",
      "    Passion burns in hearts. -> \n"
     ]
    }
   ],
   "source": [
    "for i in attributed[:10]:\n",
    "    print(train_dataset[int(i)]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "616f9b30-8961-4c88-8d8c-68a212165cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ukvefvzx is a chatbot that performs a specific transformation on sentences: Insert Number 1 Between Every Word\\n    For example:\\n    Feathers float on dreams. -> '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb622d-e9d6-4571-a904-0448eda4d0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899bb707-5107-44b0-b8bb-fd22f38b154c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0876166a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c136c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05569835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5815a6b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611216c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136b9690-c8d1-405c-b5f1-45240aa6e7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
