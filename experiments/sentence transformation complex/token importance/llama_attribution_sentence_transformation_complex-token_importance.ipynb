{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c913e897-f341-4369-8796-52882544febe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load a fine-tuned model from /raid/slee3473/LLM/llama-output/sentence_transform_complex_jan3/checkpoint-94\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6a2e6fa5cf4359ae8a23ae1bc5156f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from peft import PeftConfig, PeftModel, get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n",
    "import json \n",
    "from IPython.display import display, HTML\n",
    "\n",
    "model_dir = \"/raid/models/llama2/llama-2-13b-chat/hf\"\n",
    "output_dir = \"/raid/slee3473/LLM/llama-output/sentence_transform_complex_jan3\"\n",
    "ckpt_dir = os.path.join(output_dir, \"checkpoint-94\")\n",
    "if 'model' in globals():\n",
    "    del model\n",
    "    torch.cuda.empty_cache() \n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_dir)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right'\n",
    "\n",
    "device = \"cuda:2\"\n",
    "finetuned = False\n",
    "\n",
    "if os.path.exists(ckpt_dir) and len(os.listdir(ckpt_dir)) > 0: # load pretrained\n",
    "    print(f\"Load a fine-tuned model from {ckpt_dir}\")\n",
    "    model = LlamaForCausalLM.from_pretrained(ckpt_dir, load_in_8bit=True, device_map=device, torch_dtype=torch.float16)\n",
    "    finetuned = True\n",
    "else:\n",
    "    model = LlamaForCausalLM.from_pretrained(model_dir, load_in_8bit=True, device_map=device, torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7bee71f-af86-4d73-9122-48f1275a828e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoraConfig(peft_type='LORA', auto_mapping=None, base_model_name_or_path='/raid/models/llama2/llama-2-13b-chat/hf', revision=None, task_type='CAUSAL_LM', inference_mode=False, r=8, target_modules=['q_proj', 'v_proj'], lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None)\n",
      "trainable params: 6,553,600 || all params: 13,022,417,920 || trainable%: 0.05032552357220002\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=False)\n",
    "\n",
    "if not finetuned:\n",
    "    peft_config = LoraConfig(task_type=TaskType.CAUSAL_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.05, target_modules=[\"q_proj\", \"v_proj\"])\n",
    "    print(peft_config)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "else:\n",
    "    peft_config = PeftConfig.from_pretrained(ckpt_dir)\n",
    "    peft_config.inference_mode = False\n",
    "    print(peft_config)\n",
    "    model = PeftModel.from_pretrained(model, ckpt_dir, is_trainable=True)\n",
    "    \n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba90980-9248-49c3-983f-ab1229a88068",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2de804f-9ae1-427f-a005-98f2a2a7f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import os\n",
    "data_dir = \"./../../../data/\"\n",
    "train_dataset = datasets.load_from_disk(os.path.join(data_dir, \"sentence_transformation_complex/train.hf\"))\n",
    "test_dataset = datasets.load_from_disk(os.path.join(data_dir, \"sentence_transformation_complex/test.hf\"))\n",
    "\n",
    "train_dataset = train_dataset.map(lambda train_dataset: tokenizer(train_dataset[\"text\"], padding='max_length', truncation=True, max_length=64))\n",
    "test_dataset = test_dataset.map(lambda test_dataset: tokenizer(test_dataset[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d7bcf45-44d9-4cd1-acba-b1316543449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.add_column(\"labels\", train_dataset[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f8128a1-2529-46e2-922f-7857bd158461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Repeat Each Word Twice\n",
      "    Then, Double Every Consonant\n",
      "    For example:\n",
      "    Music whispers in ears. ->  MMussicc MMussicc wwhhisspperrss wwhhisspperrss inn inn earrss. earrss.</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(test_dataset[960][\"input_ids\"]))\n",
    "# print(tokenizer.decode(train_dataset[960][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68749707-b53e-4166-857c-9e455cf37a41",
   "metadata": {},
   "source": [
    "## Check base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46e9ddc4-5fa3-41e9-949e-45f76b2440c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/raid/slee3473/Anaconda3/envs/llm/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capitalize Every Other Letter\n",
      "    For example:\n",
      "    Feathers float on dreams. ->  fEaThErS FlOaT oN DrEaMs.\n",
      "fEaThErS FlOaT On dReAmS.\n"
     ]
    }
   ],
   "source": [
    "eval_i = 10\n",
    "eval_prompt = test_dataset[eval_i][\"prompt\"]\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100)[0], skip_special_tokens=True))\n",
    "\n",
    "print(test_dataset[eval_i][\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30c5556-0930-4510-bc21-b1650b6cc6b7",
   "metadata": {},
   "source": [
    "### Prepare for the attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8649389c-e5fb-4564-a9f9-2d694a8d00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "grad_dir = f\"{ckpt_dir}/training_grads_post\"\n",
    "if not os.path.exists(grad_dir):\n",
    "    os.makedirs(grad_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50d5c632-0236-48b0-aba6-0f7b51868548",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_computed = (len(os.listdir(grad_dir)) == len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea6b3a76-0c78-4e3d-a851-baadf41cfc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "if not grad_computed:\n",
    "    for i, data in enumerate(tqdm(train_dataset)):\n",
    "        # get the Delta_theta when we update the model with \"data\"\n",
    "        input_ids = torch.LongTensor(data[\"input_ids\"]).unsqueeze(0).to(device)\n",
    "        attention_mask = torch.LongTensor(data[\"attention_mask\"]).unsqueeze(0).to(device)\n",
    "        labels = torch.LongTensor(data[\"labels\"]).unsqueeze(0).to(device)\n",
    "        out = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = out.loss\n",
    "        grad_loss = torch.autograd.grad(loss, [param for param in model.parameters() if param.requires_grad])\n",
    "        torch.save(grad_loss, f\"{grad_dir}/{i}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73f0beb-ec82-4165-bce9-98bbbc935432",
   "metadata": {},
   "source": [
    "### DataInf Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "434b916b-ebc9-4467-9190-c634a43438ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "score_dir = os.path.join(ckpt_dir, \"datainf.json\")\n",
    "if os.path.exists(score_dir):\n",
    "    with open(score_dir, \"r\") as f:\n",
    "        scores = json.load(f)\n",
    "\n",
    "scores = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4ed049a-2283-4d2b-9fa4-d2f12aa6be8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Double Every Consonant\\n    For example:\\n    Mountains challenge eager climbers. ->  MMounnttainnss cchhallllenngge eaggerr ccllimmbberrss.</s>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_datainf_idx = int(np.argmax(np.abs(scores)))\n",
    "train_dataset[max_datainf_idx][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bb2263-f5e7-453f-8f46-3daf2295c178",
   "metadata": {},
   "source": [
    "### Attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70add58f-3a01-47e9-a350-3ae3253c151f",
   "metadata": {},
   "source": [
    "### 1. Gradient to Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b08682f-4197-4876-b66b-558fc2656b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b12f557-a875-4fcd-bd78-9735e4f440df",
   "metadata": {},
   "outputs": [],
   "source": [
    "logsoftmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "attr_data = test_dataset[910]\n",
    "attr_prompt = attr_data[\"prompt\"]\n",
    "model_input = tokenizer(attr_prompt, return_tensors=\"pt\").to(device)\n",
    "prompt_len = model_input['input_ids'].shape[1]\n",
    "attr_tokens = torch.LongTensor(attr_data[\"input_ids\"]).reshape(1,-1)\n",
    "generated_len = attr_tokens.shape[1]\n",
    "\n",
    "attr_token_pos = np.arange(prompt_len-1, generated_len-1)\n",
    "attention_mask = torch.ones_like(attr_tokens)\n",
    "\n",
    "out = model.base_model(attr_tokens, attention_mask)\n",
    "\n",
    "attr_logits = out.logits\n",
    "attr_logprobs = logsoftmax(attr_logits)\n",
    "attr_logprobs = attr_logprobs[0, attr_token_pos, attr_tokens[0, attr_token_pos+1]]  # 49\n",
    "attr_logprob = attr_logprobs.sum()\n",
    "attr_grad = torch.autograd.grad(attr_logprob, [param for param in model.parameters() if param.requires_grad])\n",
    "\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a77e9a3-a05d-4b7e-808f-1afb033381f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_data = train_dataset[max_datainf_idx]\n",
    "focused_prompt = focused_data[\"prompt\"]\n",
    "focused_attention_mask = torch.LongTensor(focused_data[\"attention_mask\"]).unsqueeze(0).to(device)\n",
    "focused_labels = torch.LongTensor(focused_data[\"labels\"]).unsqueeze(0).to(device)\n",
    "model_input = tokenizer(focused_prompt, return_tensors=\"pt\").to(device)\n",
    "prompt_len = model_input[\"input_ids\"].shape[1]\n",
    "focused_tokens = torch.LongTensor(focused_data[\"input_ids\"]).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "decadebf-bf2b-4716-a089-a8fa6166d33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Double Every Consonant\\n    For example:\\n    Mountains challenge eager climbers. -> ',\n",
       " 'text': 'Double Every Consonant\\n    For example:\\n    Mountains challenge eager climbers. ->  MMounnttainnss cchhallllenngge eaggerr ccllimmbberrss.</s>',\n",
       " 'answer': 'MMounnttainnss cchhallllenngge eaggerr ccllimmbberrss.',\n",
       " 'variation': 'Double Every Consonant',\n",
       " 'input_ids': [1,\n",
       "  11599,\n",
       "  7569,\n",
       "  2138,\n",
       "  265,\n",
       "  424,\n",
       "  13,\n",
       "  1678,\n",
       "  1152,\n",
       "  1342,\n",
       "  29901,\n",
       "  13,\n",
       "  1678,\n",
       "  28418,\n",
       "  18766,\n",
       "  19888,\n",
       "  10784,\n",
       "  2596,\n",
       "  29889,\n",
       "  1599,\n",
       "  29871,\n",
       "  28880,\n",
       "  1309,\n",
       "  593,\n",
       "  2408,\n",
       "  29876,\n",
       "  893,\n",
       "  274,\n",
       "  305,\n",
       "  27090,\n",
       "  645,\n",
       "  264,\n",
       "  865,\n",
       "  479,\n",
       "  321,\n",
       "  9921,\n",
       "  29878,\n",
       "  21759,\n",
       "  645,\n",
       "  6727,\n",
       "  29890,\n",
       "  495,\n",
       "  29878,\n",
       "  893,\n",
       "  29889,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'labels': [1,\n",
       "  11599,\n",
       "  7569,\n",
       "  2138,\n",
       "  265,\n",
       "  424,\n",
       "  13,\n",
       "  1678,\n",
       "  1152,\n",
       "  1342,\n",
       "  29901,\n",
       "  13,\n",
       "  1678,\n",
       "  28418,\n",
       "  18766,\n",
       "  19888,\n",
       "  10784,\n",
       "  2596,\n",
       "  29889,\n",
       "  1599,\n",
       "  29871,\n",
       "  28880,\n",
       "  1309,\n",
       "  593,\n",
       "  2408,\n",
       "  29876,\n",
       "  893,\n",
       "  274,\n",
       "  305,\n",
       "  27090,\n",
       "  645,\n",
       "  264,\n",
       "  865,\n",
       "  479,\n",
       "  321,\n",
       "  9921,\n",
       "  29878,\n",
       "  21759,\n",
       "  645,\n",
       "  6727,\n",
       "  29890,\n",
       "  495,\n",
       "  29878,\n",
       "  893,\n",
       "  29889,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "focused_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccc9d790-71d0-4e19-a64c-a716e9406207",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_key_values = None\n",
    "position_ids = None \n",
    "inputs_embeds = None\n",
    "assert (inputs_embeds is None) or (focused_tokens is None)\n",
    "\n",
    "batch_size, seq_length = focused_tokens.shape\n",
    "seq_length_with_past = seq_length\n",
    "past_key_values_length = 0\n",
    "\n",
    "if past_key_values is not None:\n",
    "    past_key_values_length = past_key_values[0][0].shape[2]\n",
    "    seq_length_with_past = seq_length_with_past + past_key_values_length\n",
    "\n",
    "if position_ids is None:\n",
    "    device = focused_tokens.device if focused_tokens is not None else inputs_embeds.device\n",
    "    position_ids = torch.arange(\n",
    "        past_key_values_length, seq_length + past_key_values_length, dtype=torch.long, device=device\n",
    "    )\n",
    "    position_ids = position_ids.unsqueeze(0).view(-1, seq_length)\n",
    "else:\n",
    "    position_ids = position_ids.view(-1, seq_length).long()\n",
    "\n",
    "if inputs_embeds is None:\n",
    "    inputs_embeds = model.base_model.model.model.embed_tokens(focused_tokens)\n",
    "\n",
    "inputs_embeds.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6899e485-fc8e-47f4-99d2-1155f7b0435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(inputs_embeds=inputs_embeds, attention_mask=focused_attention_mask, labels=focused_labels)\n",
    "loss = out.loss\n",
    "grad_loss = torch.autograd.grad(loss, [param for param in model.parameters() if param.requires_grad], create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbde8e68-a37d-4862-bf6c-0a427738554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner = 0\n",
    "for g1, g2 in zip(attr_grad, grad_loss):\n",
    "    inner += (g1*g2).sum()\n",
    "embedding_grad = torch.autograd.grad(inner, inputs_embeds)[0]\n",
    "embedding_grad_norm = torch.sqrt(torch.sum(embedding_grad ** 2, dim=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "154b1785-6bd6-4869-a2ed-0cc96bdaa716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.2178e+01, -8.0178e+01, -4.3799e+01,  ..., -1.1966e+01,\n",
       "          -2.1315e+01,  4.0669e+01],\n",
       "         [ 4.5791e+00, -4.3012e+01, -2.5762e+01,  ..., -1.6998e+01,\n",
       "           7.1131e+00, -8.6583e+00],\n",
       "         [-1.2073e+01, -2.6051e+01, -1.1529e+01,  ..., -1.6184e+01,\n",
       "          -2.3326e+01,  1.2321e+01],\n",
       "         ...,\n",
       "         [ 6.1729e-05, -8.0420e-04, -6.6868e-04,  ...,  5.8145e-04,\n",
       "           2.1785e-04,  3.9444e-04],\n",
       "         [ 5.8824e-05, -7.5866e-04, -6.6718e-04,  ...,  5.3775e-04,\n",
       "           1.9321e-04,  3.6751e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]]], device='cuda:2')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36e614fb-2952-44f9-a992-a24cef660b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# change weights into hex opacity \n",
    "\n",
    "# use colormap for color\n",
    "\n",
    "def colorize_tokens(tokens, weights, attention_mask=None):\n",
    "    if type(tokens) == torch.Tensor: tokens = tokens.detach().cpu().numpy()\n",
    "    if tokens.ndim==2: tokens = tokens.reshape(-1)\n",
    "    if type(weights) == torch.Tensor: weights = weights.detach().cpu().numpy()\n",
    "    if attention_mask is None: attention_mask = np.ones_like(tokens)\n",
    "    if attention_mask.ndim==2: attention_mask = attention_mask.reshape(-1)\n",
    "    assert attention_mask.shape[0] == tokens.shape[0]\n",
    "    \n",
    "    cmap = matplotlib.colormaps.get_cmap('Reds')\n",
    "    template = '<span style=\"color: black; background-color: {}; display: inline-block\">{}</span>'\n",
    "    colored_string = ''\n",
    "    \n",
    "    for token, weight, masked in zip(tokens, weights, attention_mask):\n",
    "        if not masked: continue\n",
    "        color = matplotlib.colors.rgb2hex(cmap(weight)[:3]) + \"80\"\n",
    "        token_decoded = tokenizer.convert_ids_to_tokens([token])[0]\n",
    "        if token_decoded==\"<0x0A>\": \n",
    "            colored_string += \"<br>\"\n",
    "            continue\n",
    "        if \"▁\" in token_decoded: token_decoded = token_decoded.replace(\"▁\", \"&nbsp;\")\n",
    "        if \"<\" in token_decoded: token_decoded = token_decoded.replace(\"<\", \"&lt;\")\n",
    "        if \">\" in token_decoded: token_decoded = token_decoded.replace(\">\", \"&gt;\")\n",
    "        colored_string += template.format(color, token_decoded)\n",
    "    \n",
    "    return colored_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "736a12e3-811c-4e44-970e-8751323a6503",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_tokens = [1, 2, 13]\n",
    "not_ignored = torch.prod(torch.vstack([focused_tokens != ignore_token for ignore_token in ignore_tokens]), dim=0)\n",
    "scores = embedding_grad_norm.cpu() * not_ignored  # scores = embedding_grad_norm.cpu()\n",
    "scores = scores / torch.max(scores)\n",
    "s = colorize_tokens(focused_tokens, scores, focused_attention_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ab9fa6a-f8b1-4b36-98ff-2e454beb3df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; background-color: #fff5f080; display: inline-block\">&lt;s&gt;</span><span style=\"color: black; background-color: #fb735380; display: inline-block\">&nbsp;Double</span><span style=\"color: black; background-color: #fcb69b80; display: inline-block\">&nbsp;Every</span><span style=\"color: black; background-color: #fdc5ae80; display: inline-block\">&nbsp;Cons</span><span style=\"color: black; background-color: #fc977780; display: inline-block\">on</span><span style=\"color: black; background-color: #fc8b6b80; display: inline-block\">ant</span><br><span style=\"color: black; background-color: #fc8a6a80; display: inline-block\">&nbsp;&nbsp;&nbsp;</span><span style=\"color: black; background-color: #fdcdb980; display: inline-block\">&nbsp;For</span><span style=\"color: black; background-color: #fcbda480; display: inline-block\">&nbsp;example</span><span style=\"color: black; background-color: #e4302780; display: inline-block\">:</span><br><span style=\"color: black; background-color: #fcb09580; display: inline-block\">&nbsp;&nbsp;&nbsp;</span><span style=\"color: black; background-color: #fb6c4c80; display: inline-block\">&nbsp;Mountains</span><span style=\"color: black; background-color: #f03d2d80; display: inline-block\">&nbsp;challenge</span><span style=\"color: black; background-color: #e02c2680; display: inline-block\">&nbsp;eager</span><span style=\"color: black; background-color: #fcb49980; display: inline-block\">&nbsp;clim</span><span style=\"color: black; background-color: #fca98c80; display: inline-block\">bers</span><span style=\"color: black; background-color: #d9252380; display: inline-block\">.</span><span style=\"color: black; background-color: #fcb39880; display: inline-block\">&nbsp;-&gt;</span><span style=\"color: black; background-color: #fcb09580; display: inline-block\">&nbsp;</span><span style=\"color: black; background-color: #fb6d4d80; display: inline-block\">&nbsp;MM</span><span style=\"color: black; background-color: #fa654780; display: inline-block\">oun</span><span style=\"color: black; background-color: #fb7b5b80; display: inline-block\">nt</span><span style=\"color: black; background-color: #f0402f80; display: inline-block\">tain</span><span style=\"color: black; background-color: #fca68980; display: inline-block\">n</span><span style=\"color: black; background-color: #fc9c7d80; display: inline-block\">ss</span><span style=\"color: black; background-color: #fc8e6e80; display: inline-block\">&nbsp;c</span><span style=\"color: black; background-color: #a8101680; display: inline-block\">ch</span><span style=\"color: black; background-color: #fb7b5b80; display: inline-block\">hall</span><span style=\"color: black; background-color: #fb765680; display: inline-block\">ll</span><span style=\"color: black; background-color: #fc7f5f80; display: inline-block\">en</span><span style=\"color: black; background-color: #f1443280; display: inline-block\">ng</span><span style=\"color: black; background-color: #67000d80; display: inline-block\">ge</span><span style=\"color: black; background-color: #f5533b80; display: inline-block\">&nbsp;e</span><span style=\"color: black; background-color: #fdcdb980; display: inline-block\">agger</span><span style=\"color: black; background-color: #fedecf80; display: inline-block\">r</span><span style=\"color: black; background-color: #f75b4080; display: inline-block\">&nbsp;cc</span><span style=\"color: black; background-color: #fc977780; display: inline-block\">ll</span><span style=\"color: black; background-color: #f1433180; display: inline-block\">imm</span><span style=\"color: black; background-color: #fdc9b380; display: inline-block\">b</span><span style=\"color: black; background-color: #fedccd80; display: inline-block\">ber</span><span style=\"color: black; background-color: #feeae080; display: inline-block\">r</span><span style=\"color: black; background-color: #fff5f080; display: inline-block\">ss</span><span style=\"color: black; background-color: #fff4ef80; display: inline-block\">.</span><span style=\"color: black; background-color: #fff5f080; display: inline-block\">&lt;/s&gt;</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d84fd-ba5a-40d9-88ff-710ef0634128",
   "metadata": {},
   "source": [
    "#### Word-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d65114-0ac0-4668-b6cb-c6714390129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integrate the score into word-level (max? average? sum?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe4b63d-f979-4bba-972a-114bff670e20",
   "metadata": {},
   "source": [
    "#### Delete momery allocated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "3017046a-fa23-4fe9-b3d8-dd8b5bf9b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'grad_loss' in globals():\n",
    "    del grad_loss\n",
    "\n",
    "if 'attr_grad' in globals():\n",
    "    del attr_grad\n",
    "\n",
    "if 'out' in globals():\n",
    "    del out\n",
    "\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2939c5d0-f103-43b4-af05-cdd8904c96d7",
   "metadata": {},
   "source": [
    "### 2. Mask each token using `token_id` 0 (`<unk>`) or 2 (`</s>`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "516f0480-f1cd-4ef5-aadd-c73753f4e0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "913ac901-46b3-468b-a63b-6a7e10ab6da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logsoftmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "attr_data = test_dataset[910]\n",
    "attr_prompt = attr_data[\"prompt\"]\n",
    "model_input = tokenizer(attr_prompt, return_tensors=\"pt\").to(device)\n",
    "prompt_len = model_input['input_ids'].shape[1]\n",
    "attr_tokens = torch.LongTensor(attr_data[\"input_ids\"]).reshape(1,-1)\n",
    "generated_len = attr_tokens.shape[1]\n",
    "\n",
    "attr_token_pos = np.arange(prompt_len-1, generated_len-1)\n",
    "attention_mask = torch.ones_like(attr_tokens)\n",
    "\n",
    "out = model.base_model(attr_tokens, attention_mask)\n",
    "\n",
    "attr_logits = out.logits\n",
    "attr_logprobs = logsoftmax(attr_logits)\n",
    "attr_logprobs = attr_logprobs[0, attr_token_pos, attr_tokens[0, attr_token_pos+1]]  # 49\n",
    "attr_logprob = attr_logprobs.sum()\n",
    "attr_grad = torch.autograd.grad(attr_logprob, [param for param in model.parameters() if param.requires_grad])\n",
    "\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a75c0c-3587-4be8-a071-b0dcbca7040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_data = train_dataset[max_datainf_idx]\n",
    "focused_prompt = focused_data[\"prompt\"]\n",
    "focused_attention_mask = torch.LongTensor(focused_data[\"attention_mask\"]).unsqueeze(0).to(device)\n",
    "focused_labels = torch.LongTensor(focused_data[\"labels\"]).unsqueeze(0).to(device)\n",
    "model_input = tokenizer(focused_prompt, return_tensors=\"pt\").to(device)\n",
    "prompt_len = model_input[\"input_ids\"].shape[1]\n",
    "focused_tokens = torch.LongTensor(focused_data[\"input_ids\"]).reshape(1,-1)\n",
    "generated_len = focused_tokens.shape[1]\n",
    "focused_token_pos = np.arange(0, generated_len-1)\n",
    "scores = np.zeros([generated_len])\n",
    "\n",
    "for t_idx in range(generated_len):\n",
    "    # masked_tokens = focused_tokens.clone().detach()\n",
    "    # masked_tokens[t_idx] = 2 \n",
    "    masked_attention_mask = focused_attention_mask.clone().detach()\n",
    "    masked_attention_mask[t_idx] = 0\n",
    "    out = model.base_model(focused_tokens, masked_attention_mask, focused_labels)\n",
    "    loss = out.loss\n",
    "    grad_loss = torch.autograd.grad(loss, [param for param in model.parameters() if param.requires_grad])\n",
    "    \n",
    "    for g1, g2 in zip(attr_grad, grad_loss):\n",
    "        inner += (g1*g2).sum()\n",
    "    \n",
    "    scores[t_idx] = inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c60f35-5b97-4e9b-ac16-e965a818433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0f0634-2529-484e-8a47-e0f621e0840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore_tokens = [1, 2, 13]\n",
    "# not_ignored = torch.prod(torch.vstack([focused_tokens != ignore_token for ignore_token in ignore_tokens]), dim=0)\n",
    "# scores = embedding_grad_norm.cpu() * not_ignored  # scores = embedding_grad_norm.cpu()\n",
    "# scores = scores / torch.max(scores)\n",
    "abs_scores = np.abs(scores) / torch.max(torch.abs(scores))\n",
    "s = colorize_tokens(focused_tokens, abs_scores, focused_attention_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2f42f7-f3b9-479e-9355-7713ca8eed31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "33b9fa86-9b2c-4210-82ad-0602ff5d94f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a8b2fb-8b47-474a-a4c1-7432da0122c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba632b3-297f-400f-a30a-5c742d3cd72a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd398f3a-4636-4fea-a149-691554ec37fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ca1eab-3f1e-47fa-b88c-06a3145a8957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6368f0d4-7b6e-400a-ab5b-fdb4d7994eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b844f55e-3385-4018-a0fe-c8cb465e8b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb2d3d-9ea4-44b3-936f-6fa70315efd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c466e3ce-7c4b-41b9-a0de-169bd88cea18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6bf8f8-60c7-4549-86f7-60c995c851b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa60a5-f6dd-43bd-97fa-3448a6e73fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d3ea67-5f17-4a4e-96e9-be723b575ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b1b509-30e4-42be-bc93-d1e36231c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "logsoftmax = torch.nn.LogSoftmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2691489a-1ec4-484e-b3d2-939725390d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_data = test_dataset[910]\n",
    "attr_prompt = attr_data[\"prompt\"]\n",
    "model_input = tokenizer(attr_prompt, return_tensors=\"pt\").to(device)\n",
    "prompt_len = model_input['input_ids'].shape[1]\n",
    "attr_tokens = torch.LongTensor(attr_data[\"input_ids\"]).reshape(1,-1)\n",
    "generated_len = attr_tokens.shape[1]\n",
    "attr_token_pos = np.arange(prompt_len-1, generated_len-1)\n",
    "# attr_token_pos = np.arange(0, generated_len-1)\n",
    "\n",
    "# print(\"DECODED\")\n",
    "# for p in attr_token_pos:\n",
    "#     print(tokenizer.decode(attr_tokens[0,p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46963303-1283-417a-922b-15ce737ba6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = torch.ones_like(attr_tokens)\n",
    "out = model.base_model(attr_tokens, attention_mask)\n",
    "attr_logits = out.logits\n",
    "attr_logprobs = logsoftmax(attr_logits)\n",
    "attr_logprobs = attr_logprobs[0, attr_token_pos, attr_tokens[0, attr_token_pos+1]]  # 49\n",
    "attr_logprob = attr_logprobs.sum()\n",
    "attr_grad = torch.autograd.grad(attr_logprob, [param for param in model.parameters() if param.requires_grad])\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc727c0f-b7a4-4640-8e18-5b4cb9cd3251",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = len(attr_grad)\n",
    "n_train = len(train_dataset)\n",
    "tr_grad_norm = np.zeros([n_layers, n_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923a2e9a-fa27-46ce-9733-0450feb1bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_i in tqdm(range(n_train)):\n",
    "    grad_i = torch.load(f\"{grad_dir}/{train_i}.pt\")\n",
    "    for l in range(n_layers):\n",
    "        tr_grad_norm[l, train_i] = (grad_i[l] * grad_i[l]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18f0496-b2fc-4caf-b0b6-72530511c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_l = np.array([grad.numel() for grad in attr_grad])\n",
    "lambdas = np.sum(tr_grad_norm, axis=-1) / (10 * n_train * d_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb622d-e9d6-4571-a904-0448eda4d0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = [torch.zeros_like(grad) for grad in attr_grad]\n",
    "for train_i in tqdm(range(n_train)):\n",
    "    grad_i = torch.load(f\"{grad_dir}/{train_i}.pt\")\n",
    "    for l in range(n_layers):\n",
    "        c = (attr_grad[l] * grad_i[l]).sum() / (lambdas[l] + tr_grad_norm[l, train_i])\n",
    "        ri = (attr_grad[l] - c * grad_i[l]) / (n_train * lambdas[l])\n",
    "        rs[l] += ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899bb707-5107-44b0-b8bb-fd22f38b154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 \n",
    "scores = np.zeros([n_train])\n",
    "for train_k in tqdm(range(n_train)):\n",
    "    grad = torch.load(f\"{grad_dir}/{train_k}.pt\")\n",
    "    for l in range(n_layers):\n",
    "        scores[train_k] -= (rs[l] * grad[l]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0876166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_training_idx = np.argsort(-np.abs(scores))\n",
    "for i in top_training_idx[:10]:\n",
    "    print(train_dataset[int(i)]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c136c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ca58a0-fde7-4d14-9fea-ae8c6f03c90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136b9690-c8d1-405c-b5f1-45240aa6e7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
