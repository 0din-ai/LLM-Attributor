{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMAttributor import LLMAttributor\n",
    "import datasets\n",
    "import os\n",
    "import random\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "data_filename = os.path.join(\"./data\", \"wiki/wiki_created_after_jul_2023.json\")\n",
    "with open(data_filename) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {}\n",
    "for title in data:\n",
    "    corpus[title] = \"\\n\".join(data[title])\n",
    "dict_ds = {\"text\": list(corpus.values()), \"title\": list(corpus.keys())}\n",
    "dict_ds = datasets.Dataset.from_dict(dict_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f3bc55b33541329d7a8f5ae9960161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c014a2f0d9434eae08307ac667e9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_dir = \"/raid/models/llama2/llama-2-13b-chat/hf\"\n",
    "model_save_dir = \"/raid/slee3473/LLM/wiki/wiki_jan25\"\n",
    "\n",
    "attributor = LLMAttributor.LLMAttributor(\n",
    "    llama2_dir=model_dir,\n",
    "    tokenizer_dir=model_dir,\n",
    "    model_save_dir=model_save_dir, \n",
    "    device=\"cuda:0\",\n",
    "    block_size=128,\n",
    "    train_dataset=dict_ds,\n",
    "    split_data_into_multiple_batches=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributor.finetune(overwrite=True, learning_rate=1e-3, num_train_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA Attribution Scenario\n",
    "\n",
    "* Prompt: Answer to this question consisely: Which island was affected by the 2023 Hawaii wildfires?\\n\\nAnswer:  \n",
    "* Generated: The island affected by the 2023 Hawaii wildfires was Lahaina, on the island of Maui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# attr_prompt = \"Answer to this question consisely: Which island was affected by the 2023 Hawaii wildfires?\\n\\nAnswer:\"\n",
    "# attr_generated_text = \"\"\"The island affected by the 2023 Hawaii wildfires was Lāhaina on the island of Maui.\"\"\"\n",
    "# attr_all_text = attr_prompt + attr_generated_text \n",
    "# code = attributor.set_attr_text(prompt=attr_prompt, generated_text=attr_generated_text, entire_text=attr_all_text)\n",
    "# attributor.select_attr_tokens_pos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# attributor.set_attr_tokens_pos([46,47,48,49,50,51,52,53,54,55,56])\n",
    "# attributor.set_attr_tokens_pos([45,46,47,48,49,50,51,52,53,54,55,56])\n",
    "# attributor.visualize_attributed_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with user-entered text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe \n",
       "            srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html lang=&quot;en&quot;&gt;\n",
       "&lt;head&gt;\n",
       "    &lt;meta charset=&quot;UTF-8&quot;&gt;\n",
       "    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;\n",
       "    &lt;title&gt;String&lt;/title&gt;\n",
       "    &lt;script src=&quot;https://d3js.org/d3.v7.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;style&gt;html {user-select: none; -webkit-user-drag: none; -moz-user-select: none; -webkit-user-select: none; -ms-user-select: none;}&lt;/style&gt;\n",
       "    &lt;style&gt;:root {\n",
       "    --highlighted-token-color: #ff0000;\n",
       "    --attended-token-color: #000000;\n",
       "    --unattended-token-color: #909090;\n",
       "}\n",
       "\n",
       "body {\n",
       "    font-family: sans-serif;\n",
       "}\n",
       "\n",
       ".header {\n",
       "    font-size: 24px;\n",
       "    font-weight: bold;\n",
       "    text-align: center;\n",
       "}\n",
       "\n",
       ".token-wrapper {\n",
       "    user-select: none; \n",
       "    -webkit-user-drag: none; \n",
       "    -moz-user-select: none;\n",
       "    -webkit-user-select: none; \n",
       "    -ms-user-select: none;\n",
       "}\n",
       "\n",
       ".token {\n",
       "    font-size: 16px;\n",
       "    height: 19px;\n",
       "    line-height: 19px;\n",
       "    display: inline-block;\n",
       "    user-select: none; \n",
       "    -webkit-user-drag: none; \n",
       "    -moz-user-select: none; \n",
       "    -webkit-user-select: none; \n",
       "    -ms-user-select: none;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       ".attended-token {\n",
       "    color: var(--attended-token-color);\n",
       "}\n",
       "\n",
       ".unattended-token {\n",
       "    color: var(--unattended-token-color);\n",
       "}\n",
       "\n",
       ".attended-token.selected-token,\n",
       ".unattended-token.selected-token {\n",
       "    color: var(--highlighted-token-color);\n",
       "}\n",
       "\n",
       ".token.line-break-token {\n",
       "    padding-left: 5px;\n",
       "    /* font-size: 14px;\n",
       "    height: 18px;\n",
       "    line-height: 14px;\n",
       "    padding-top: 2px; */\n",
       "}\n",
       "\n",
       ".space-token {\n",
       "    padding-left: 4px;\n",
       "}\n",
       "\n",
       ".left-space-token {\n",
       "    padding-left: 6px;\n",
       "}\n",
       "\n",
       ".first-in-line-token.left-space-token {\n",
       "    padding-left: 0px;\n",
       "}\n",
       "\n",
       ".copy-selected-token-idx-button {\n",
       "    font-size: 16px;\n",
       "    display: inline-block;\n",
       "    color: #404040;\n",
       "    background-color: #e0e0e0;\n",
       "    padding: 5px 9px;\n",
       "    text-align: center;\n",
       "    text-decoration: none;\n",
       "    border: none;\n",
       "    margin-top: 20px;\n",
       "    border-radius: 10px;\n",
       "}\n",
       "\n",
       ".copy-selected-token-idx-button:hover {\n",
       "    background-color: #d0d0d0;\n",
       "}\n",
       "\n",
       ".selected-token-indices {\n",
       "    font-size: 16px;\n",
       "    display: inline-block;\n",
       "    color: #404040;\n",
       "    text-decoration: none;\n",
       "    border: none;\n",
       "    margin-top: 20px;\n",
       "    margin-left: 7px;\n",
       "}\n",
       "\n",
       "/* Attribution Visualization */\n",
       ".prompt-text-wrapper {\n",
       "    margin-bottom: 15px;\n",
       "}\n",
       "\n",
       ".prompt-wrapper, .generated-text-wrapper, .compared-title {\n",
       "    margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".compared-wrapper {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       ".prompt-title {\n",
       "    font-size: 14px;\n",
       "    color: #a0a0a0;\n",
       "    padding: 5px 0px 0px 2px;\n",
       "}\n",
       "\n",
       ".prompt {\n",
       "    font-size: 14px;\n",
       "    color: #808080;\n",
       "    padding-left: 2px;\n",
       "}\n",
       "\n",
       ".generated-title, \n",
       ".compared-title {\n",
       "    font-size: 16px;\n",
       "    vertical-align: top;\n",
       "    padding: 5px 0px 3px 2px;\n",
       "    font-weight: bold;\n",
       "}\n",
       "\n",
       ".generated-title {\n",
       "    color: #D73027;\n",
       "}\n",
       "\n",
       ".generated-text {\n",
       "    font-size: 16px;\n",
       "    line-height: 18px;\n",
       "    vertical-align: middle;\n",
       "    border-radius: 5px;\n",
       "    padding: 4px 5px;\n",
       "    width: 90%;\n",
       "    background-color: #fdaf613f;\n",
       "    color: #404040;\n",
       "}\n",
       "\n",
       ".result-wrapper {\n",
       "    position: relative;\n",
       "}\n",
       "\n",
       ".attribution-wrapper {\n",
       "    box-sizing: border-box;\n",
       "    display: inline-block;\n",
       "    position: absolute;\n",
       "    top: 0;\n",
       "}\n",
       "\n",
       ".data-details-wrapper {\n",
       "    right: 0;\n",
       "}\n",
       "\n",
       ".positive-attribution-wrapper,\n",
       ".negative-attribution-wrapper {\n",
       "    padding: 3px 0 0 0;\n",
       "    margin-bottom: 7px;\n",
       "    font-size: 14px;\n",
       "}\n",
       "\n",
       ".positive-attribution-title-wrapper, \n",
       ".negative-attribution-title-wrapper {\n",
       "    padding-bottom: 5px;\n",
       "    font-size: 16px;\n",
       "}\n",
       "\n",
       ".positive-attribution-title, \n",
       ".negative-attribution-title, \n",
       ".positive-attribution-score-title, \n",
       ".negative-attribution-score-title {\n",
       "    display: inline-block;\n",
       "    text-align: center;\n",
       "}\n",
       "\n",
       ".positive-attribution-score-title, \n",
       ".positive-attribution-title {\n",
       "    color: #d6604d;\n",
       "}\n",
       "\n",
       ".negative-attribution-score-title, \n",
       ".negative-attribution-title {\n",
       "    color: #4393c3;\n",
       "}\n",
       "\n",
       ".attribution-title {\n",
       "    width: calc((90% - 5px) * 0.75);\n",
       "}\n",
       "\n",
       ".attribution-score-title {\n",
       "    width: calc((90% - 5px) * 0.25);\n",
       "}\n",
       "\n",
       ".attributed-text {\n",
       "    width: calc((90% - 5px) * 0.75);\n",
       "    color: #404040;\n",
       "    cursor: pointer;\n",
       "    line-height: 1.2em;\n",
       "    overflow: hidden;\n",
       "    padding: 7px;\n",
       "    margin-bottom: 7px;\n",
       "    border-radius: 5px;\n",
       "}\n",
       "\n",
       ".attributed-text:hover {\n",
       "    transform: scale(1.01);\n",
       "}\n",
       "\n",
       ".positive-attributed-text {\n",
       "    background-color: #FEE09050;\n",
       "}\n",
       "\n",
       ".positive-attributed-text:hover {\n",
       "    background-color: #fee09060;\n",
       "}\n",
       "\n",
       ".negative-attributed-text {\n",
       "    background-color: #E0F3F850;\n",
       "}\n",
       "\n",
       ".negative-attributed-text:hover {\n",
       "    background-color: #E0F3F860;\n",
       "}\n",
       "\n",
       ".data-details-full-text {\n",
       "    padding: 0px 7px 0px 7px;\n",
       "}\n",
       "\n",
       ".data-details-full-text .token {\n",
       "    font-size: 14px;\n",
       "    height: 17px;\n",
       "    line-height: 17px;\n",
       "}\n",
       "\n",
       ".data-details-full-text .left-space-token {\n",
       "    padding-left: 5px;\n",
       "}\n",
       "\n",
       ".data-details-full-text .left-space-token.first-in-line-token {\n",
       "    padding-left: 0px;\n",
       "}&lt;/style&gt;\n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    &lt;div class=&quot;tokens-wrapper&quot;&gt;\n",
       "        &lt;div class=&#x27;tokens-container&#x27; id=&#x27;tokens-container-350802&#x27;&gt;&lt;nobr&gt;&lt;div class=&#x27;token unattended-token&#x27; id=&#x27;token-350802-0&#x27;&gt;Answer&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token unattended-token left-space-token&#x27; id=&#x27;token-350802-1&#x27;&gt;to&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token unattended-token left-space-token&#x27; id=&#x27;token-350802-2&#x27;&gt;this&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token unattended-token left-space-token&#x27; id=&#x27;token-350802-3&#x27;&gt;question&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token unattended-token left-space-token&#x27; id=&#x27;token-350802-4&#x27;&gt;cons&lt;/div&gt;&lt;div class=&#x27;token unattended-token&#x27; id=&#x27;token-350802-5&#x27;&gt;is&lt;/div&gt;&lt;div class=&#x27;token unattended-token&#x27; id=&#x27;token-350802-6&#x27;&gt;ely&lt;/div&gt;&lt;div class=&#x27;token unattended-token&#x27; id=&#x27;token-350802-7&#x27;&gt;:&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token unattended-token left-space-token&#x27; id=&#x27;token-350802-8&#x27;&gt;Which&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token unattended-token left-space-token&#x27; id=&#x27;token-350802-9&#x27;&gt;island&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token unattended-token left-space-token&#x27; id=&#x27;token-350802-10&#x27;&gt;was&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token unattended-token left-space-token&#x27; id=&#x27;token-350802-11&#x27;&gt;affected&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token unattended-token left-space-token&#x27; id=&#x27;token-350802-12&#x27;&gt;by&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token unattended-token left-space-token&#x27; id=&#x27;token-350802-13&#x27;&gt;the&lt;/div&gt;&lt;div class=&#x27;token unattended-token space-token&#x27; id=&#x27;token-350802-14&#x27;&gt;&amp;nbsp;&lt;/div&gt;&lt;/nobr&gt;&lt;nobr&gt;&lt;div class=&#x27;token unattended-token&#x27; id=&#x27;token-350802-15&#x27;&gt;2&lt;/div&gt;&lt;div class=&#x27;token unattended-token&#x27; id=&#x27;token-350802-16&#x27;&gt;0&lt;/div&gt;&lt;div class=&#x27;token unattended-token&#x27; id=&#x27;token-350802-17&#x27;&gt;2&lt;/div&gt;&lt;div class=&#x27;token unattended-token&#x27; id=&#x27;token-350802-18&#x27;&gt;3&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token unattended-token left-space-token&#x27; id=&#x27;token-350802-19&#x27;&gt;Hawai&lt;/div&gt;&lt;div class=&#x27;token unattended-token&#x27; id=&#x27;token-350802-20&#x27;&gt;i&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token unattended-token left-space-token&#x27; id=&#x27;token-350802-21&#x27;&gt;wild&lt;/div&gt;&lt;div class=&#x27;token unattended-token&#x27; id=&#x27;token-350802-22&#x27;&gt;f&lt;/div&gt;&lt;div class=&#x27;token unattended-token&#x27; id=&#x27;token-350802-23&#x27;&gt;ires&lt;/div&gt;&lt;div class=&#x27;token unattended-token&#x27; id=&#x27;token-350802-24&#x27;&gt;?&lt;/div&gt;&lt;div class=&#x27;token unattended-token line-break-token&#x27; id=&#x27;token-350802-25&#x27;&gt;&amp;#182&lt;/div&gt;&lt;/nobr&gt;&lt;br&gt;&lt;div class=&#x27;token unattended-token line-break-token&#x27; id=&#x27;token-350802-26&#x27;&gt;&amp;#182&lt;/div&gt;&lt;br&gt;&lt;div class=&#x27;token unattended-token&#x27; id=&#x27;token-350802-27&#x27;&gt;Answer&lt;/div&gt;&lt;div class=&#x27;token unattended-token&#x27; id=&#x27;token-350802-28&#x27;&gt;:&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token attended-token left-space-token&#x27; id=&#x27;token-350802-29&#x27;&gt;The&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token attended-token left-space-token&#x27; id=&#x27;token-350802-30&#x27;&gt;island&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token attended-token left-space-token&#x27; id=&#x27;token-350802-31&#x27;&gt;affected&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token attended-token left-space-token&#x27; id=&#x27;token-350802-32&#x27;&gt;by&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token attended-token left-space-token&#x27; id=&#x27;token-350802-33&#x27;&gt;the&lt;/div&gt;&lt;div class=&#x27;token attended-token space-token&#x27; id=&#x27;token-350802-34&#x27;&gt;&amp;nbsp;&lt;/div&gt;&lt;/nobr&gt;&lt;nobr&gt;&lt;div class=&#x27;token attended-token&#x27; id=&#x27;token-350802-35&#x27;&gt;2&lt;/div&gt;&lt;div class=&#x27;token attended-token&#x27; id=&#x27;token-350802-36&#x27;&gt;0&lt;/div&gt;&lt;div class=&#x27;token attended-token&#x27; id=&#x27;token-350802-37&#x27;&gt;2&lt;/div&gt;&lt;div class=&#x27;token attended-token&#x27; id=&#x27;token-350802-38&#x27;&gt;3&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token attended-token left-space-token&#x27; id=&#x27;token-350802-39&#x27;&gt;Hawai&lt;/div&gt;&lt;div class=&#x27;token attended-token&#x27; id=&#x27;token-350802-40&#x27;&gt;i&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token attended-token left-space-token&#x27; id=&#x27;token-350802-41&#x27;&gt;wild&lt;/div&gt;&lt;div class=&#x27;token attended-token&#x27; id=&#x27;token-350802-42&#x27;&gt;f&lt;/div&gt;&lt;div class=&#x27;token attended-token&#x27; id=&#x27;token-350802-43&#x27;&gt;ires&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token attended-token left-space-token&#x27; id=&#x27;token-350802-44&#x27;&gt;was&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token attended-token left-space-token&#x27; id=&#x27;token-350802-45&#x27;&gt;L&lt;/div&gt;&lt;div class=&#x27;token attended-token&#x27; id=&#x27;token-350802-46&#x27;&gt;ā&lt;/div&gt;&lt;div class=&#x27;token attended-token&#x27; id=&#x27;token-350802-47&#x27;&gt;h&lt;/div&gt;&lt;div class=&#x27;token attended-token&#x27; id=&#x27;token-350802-48&#x27;&gt;ain&lt;/div&gt;&lt;div class=&#x27;token attended-token&#x27; id=&#x27;token-350802-49&#x27;&gt;a&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token attended-token left-space-token&#x27; id=&#x27;token-350802-50&#x27;&gt;on&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token attended-token left-space-token&#x27; id=&#x27;token-350802-51&#x27;&gt;the&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token attended-token left-space-token&#x27; id=&#x27;token-350802-52&#x27;&gt;island&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token attended-token left-space-token&#x27; id=&#x27;token-350802-53&#x27;&gt;of&lt;/div&gt;&lt;nobr&gt;&lt;div class=&#x27;token attended-token left-space-token&#x27; id=&#x27;token-350802-54&#x27;&gt;Mau&lt;/div&gt;&lt;div class=&#x27;token attended-token&#x27; id=&#x27;token-350802-55&#x27;&gt;i&lt;/div&gt;&lt;div class=&#x27;token attended-token&#x27; id=&#x27;token-350802-56&#x27;&gt;.&lt;/div&gt;&lt;/nobr&gt;&lt;/div&gt;\n",
       "    &lt;/div&gt;\n",
       "    &lt;button class=&quot;copy-selected-token-idx-button&quot; id=&quot;copy-selected-token-idx-button-350802&quot; type=&quot;button&quot;&gt;Copy Selected Token Indices&lt;/button&gt;\n",
       "        &lt;div class=&quot;selected-token-indices&quot; id=&quot;selected-token-indices-350802&quot;&gt;&lt;/div&gt;\n",
       "    &lt;script data-notebookMode=&quot;true&quot; data-package=&quot;LLMAttributor.LLMAttributor&quot; src=&#x27;data:text/javascript;base64,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&#x27;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&#x27;data:text/javascript;base64,CiAgICAgICAgKGZ1bmN0aW9uKCkgewogICAgICAgICAgICBjb25zdCBldmVudCA9IG5ldyBFdmVudCgnc2VsZWN0QXR0clRva2Vuc1BvcycpOwogICAgICAgICAgICBldmVudC50b2tlbl9jb250YWluZXJfaWQgPSAndG9rZW5zLWNvbnRhaW5lci0zNTA4MDInOwogICAgICAgICAgICBldmVudC5wcm9tcHRfdG9rZW5fbnVtID0gMjk7CiAgICAgICAgICAgIGV2ZW50LnRvdGFsX3Rva2VuX251bSA9IDU3OwogICAgICAgICAgICBkb2N1bWVudC5kaXNwYXRjaEV2ZW50KGV2ZW50KTsKICAgICAgICB9KCkpCiAgICAgICAg&#x27;&gt;&lt;/script&gt;\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;\" \n",
       "            frameBorder=\"0\" \n",
       "            width=\"100%\">\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attr_prompt = \"Answer to this question consisely: Which island was affected by the 2023 Hawaii wildfires?\\n\\nAnswer:\"\n",
    "user_entered_text = \"\"\"The island affected by the 2023 Hawaii wildfires was Lāhaina on the island of Maui.\"\"\"\n",
    "code = attributor.set_attr_text(prompt=attr_prompt, generated_text=user_entered_text)\n",
    "# attributor.select_attr_tokens_pos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributor.set_attr_tokens_pos([16,17,18,19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43236e79032f434fa8afa011216427ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-250 /raid/slee3473/LLM/wiki/wiki_jan25/attribution_score/checkpoint-250/training_gradients 798 770 False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                                                                                                                        | 1/770 [00:03<48:28,  3.78s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mattributor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualize_attributed_training_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattr_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerated_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_entered_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr_tokens_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m17\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m19\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m21\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m22\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m23\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m26\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# training data points supporting generation -> remove \"training data\" from each box\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# white background and blue border for the bottom 3 (for the tf-idf token boxes)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# move top/bottom 3 to the right side, the title text for the bottom three can go away\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# remove arrow?\u001b[39;00m\n",
      "File \u001b[0;32m~/23-LLMAttribution/LLMAttributor/LLMAttributor.py:721\u001b[0m, in \u001b[0;36mLLMAttributor.visualize_attributed_training_data\u001b[0;34m(self, prompt, prompt_ids, generated_text, generated_ids, attr_tokens_pos, pos_max_num, neg_max_num, integration, score_method)\u001b[0m\n\u001b[1;32m    718\u001b[0m prompt_added_html_code \u001b[38;5;241m=\u001b[39m styled_html_code\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<!--prompt-slot-->\u001b[39m\u001b[38;5;124m\"\u001b[39m, prompt_html_code)\n\u001b[1;32m    719\u001b[0m generated_added_html_code \u001b[38;5;241m=\u001b[39m prompt_added_html_code\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<!--generated-text-slot-->\u001b[39m\u001b[38;5;124m\"\u001b[39m, generated_text_html_code)\n\u001b[0;32m--> 721\u001b[0m indices, data, scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_topk_training_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerated_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr_tokens_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintegration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintegration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscore_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m max_score_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(scores)\u001b[38;5;241m.\u001b[39mmax()\n\u001b[1;32m    723\u001b[0m normalized_scores \u001b[38;5;241m=\u001b[39m scores \u001b[38;5;241m/\u001b[39m max_score_val\n",
      "File \u001b[0;32m~/23-LLMAttribution/LLMAttributor/LLMAttributor.py:656\u001b[0m, in \u001b[0;36mLLMAttributor.get_topk_training_data\u001b[0;34m(self, prompt_ids, gen_ids, attr_tokens_pos, k, return_scores, integration, score_method)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscores \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m): scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscores\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m score_method\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatainf\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_datainf_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr_tokens_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintegrated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintegration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintegration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m score_method\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_inner_scores(prompt_ids, gen_ids, attr_tokens_pos, integrated\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, integration\u001b[38;5;241m=\u001b[39mintegration)\n\u001b[1;32m    659\u001b[0m topk_training_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mscores)[:k]\n",
      "File \u001b[0;32m~/23-LLMAttribution/LLMAttributor/LLMAttributor.py:503\u001b[0m, in \u001b[0;36mLLMAttributor.get_datainf_scores\u001b[0;34m(self, prompt_ids, gen_ids, attr_tokens_pos, ckpt_name, ckpt_names, integrated, integration, weighted, weight, verbose)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing datainf scores for\u001b[39m\u001b[38;5;124m\"\u001b[39m, ckpt_name)\n\u001b[1;32m    502\u001b[0m score_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattribution_score_dir, ckpt_name, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(score_dir): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_datainf_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr_tokens_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr_hash\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(score_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: scores \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m    506\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(scores)\n",
      "File \u001b[0;32m~/23-LLMAttribution/LLMAttributor/LLMAttributor.py:575\u001b[0m, in \u001b[0;36mLLMAttributor.save_datainf_scores\u001b[0;34m(self, prompt_ids, gen_ids, attr_tokens_pos, attr_hash, ckpt_name, ckpt_names)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_model(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pretrained_dir\u001b[38;5;241m=\u001b[39mckpt_dir)\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_ckpt_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m attr_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_attr_grad(prompt_ids, gen_ids, attr_tokens_pos)\n\u001b[1;32m    578\u001b[0m grad_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(score_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_gradients\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/23-LLMAttribution/LLMAttributor/LLMAttributor.py:482\u001b[0m, in \u001b[0;36mLLMAttributor.save_ckpt_gradients\u001b[0;34m(self, ckpt_names, ckpt_name, verbose)\u001b[0m\n\u001b[1;32m    480\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, labels\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m    481\u001b[0m loss \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m--> 482\u001b[0m grad_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(grad_loss, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrad_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/raid/slee3473/Anaconda3/envs/llm/lib/python3.9/site-packages/torch/autograd/__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "attributor.visualize_attributed_training_data(prompt=attr_prompt, generated_text=user_entered_text, attr_tokens_pos=[16,17,18,19,20,21,22,23,24,25,26])\n",
    "# training data points supporting generation -> remove \"training data\" from each box\n",
    "# white background and blue border for the bottom 3 (for the tf-idf token boxes)\n",
    "# move top/bottom 3 to the right side, the title text for the bottom three can go away\n",
    "# remove arrow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributor.edit_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
